<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Puneet Mehrotra</title>
    <link>/project/</link>
      <atom:link href="/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© Puneet Mehrotra 2020</copyright><lastBuildDate>Thu, 20 Dec 2018 13:51:00 +0000</lastBuildDate>
    <image>
      <url>/img/portrait.jpg</url>
      <title>Projects</title>
      <link>/project/</link>
    </image>
    
    <item>
      <title>Analysing Snort with KLEE</title>
      <link>/project/formal_verification/</link>
      <pubDate>Thu, 20 Dec 2018 13:51:00 +0000</pubDate>
      <guid>/project/formal_verification/</guid>
      <description>&lt;p&gt;Verifying systems code is hard because of concurrency and inherent complexity of
the code. Understanding the invariants and other behavioral and performance
characteristics of a distributed systems is challenging because multiple nodes
communicate and coordinate together towards the task of performing a
computation.&lt;/p&gt;
&lt;p&gt;Verification methods and tools implicitly assume that the code to be verified is
deterministic. That is users of the software will provide relevant inputs, and
by verifying program behavior using all possible values of that input, a given
verification methodology can draw inferences about a system.&lt;/p&gt;
&lt;p&gt;In the case of distributed software, the assumption of implicit determinism is
void. Network software typically works in collaboration with other compute nodes
in order to fulfill the required functionality. For example, in a peer-to-peer
system, peers detect node failures using heartbeat messages. Service Oriented
Architecture is another example where a number of services communicate using a
complex chain of RPC calls. Since the underlying communication takes place in
the form of raw packets, often the program behavior can potentially change if
the packets are received out of order or packets are lost in the network.
Therefore, in this context, both the incoming data and the send/receive order
can potentially impact program behavior and consequently increase the complexity
of verification methodology.&lt;/p&gt;
&lt;p&gt;An additional challenge is attributed to concurrency. Most modern systems use
multi-threading to achieve better performance. In such a case, the outcome of a
program is a function of how individual threads are interleaved together.
Reasoning about such interleaved execution paths is hard and adds another layer
of complexity to the process of verification.&lt;/p&gt;
&lt;p&gt;Given the above challenges, we were curious about the usability of existing
symbolic execution tools for verification of system software. In particular, we
were interested in understanding how easy it is to use symbolic execution to
verify systems software that interacts with the networking stack. We, therefore,
analyzed Snort using the popular symbolic execution engine named KLEE. We
documented the challenges that we encountered along the way. We also looked at
recent research papers to understand how they approach the problem of verifying
such code.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;/files/klee_snort.pdf&#34;&gt;PDF&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Revelio</title>
      <link>/project/revelio/</link>
      <pubDate>Sat, 26 May 2018 02:30:45 +0000</pubDate>
      <guid>/project/revelio/</guid>
      <description>&lt;p&gt;&lt;strong&gt;
&lt;a href=&#34;https://github.com/artorhem/cpsc-507&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Revelio&lt;/a&gt;&lt;/strong&gt; is a tool that statically analyses Python code for known vulnerabilities. The tool provides a IDE plugin for Sublime for highlighting vulnerabilities as well as a command-line interfaces that provides the following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detection of vulnerable functions&lt;/li&gt;
&lt;li&gt;Detection of dependencies with vulnerabilities&lt;/li&gt;
&lt;li&gt;Automatic replacement of vulnerable function with safe alternatives&lt;/li&gt;
&lt;li&gt;Automatically running tests&lt;/li&gt;
&lt;li&gt;Detecting and updating outdated dependencies&lt;/li&gt;
&lt;li&gt;Downloading and analyzing of GitHub repositories as well as local files&lt;/li&gt;
&lt;li&gt;Automatically creating pull-requests to GitHub repositories to fix vulnerable functions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Currently, Revelio is just a prototype which was developed as part of a Software Engineering course.&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Download the source code of the tool&lt;/li&gt;
&lt;li&gt;Install all requirements: &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;configuration&#34;&gt;Configuration&lt;/h2&gt;
&lt;p&gt;In order for the tool to access the Github API the Github username and password need to be set as environment variables: &lt;code&gt;export GITHUB_USER=&amp;lt;user&amp;gt;&lt;/code&gt; and &lt;code&gt;export GITHUB_PASSWORD=&amp;lt;password&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;usage&#34;&gt;Usage&lt;/h2&gt;
&lt;p&gt;To analyze a local repository the path must be provided:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python cli.py --path &amp;quot;/local/path&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To analyze a remote repository on github the URL to the repository must be provided:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python cli.py --url &amp;quot;&amp;lt;URL&amp;gt;&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To access the github repository the API access token needs to be set (see Configuration).&lt;/p&gt;
&lt;h2 id=&#34;collected-data&#34;&gt;Collected Data&lt;/h2&gt;
&lt;p&gt;For analyzed github repositories metrics will be collected in &lt;code&gt;/tmp&lt;/code&gt; in &lt;code&gt;metrics.json&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;docker&#34;&gt;Docker&lt;/h2&gt;
&lt;p&gt;To build the container:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker build -t 507 .&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To run the container:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run --name 507 -v /tmp/dock:/tmp -e GITHUB_USER=&amp;quot;username&amp;quot; -e GITHUB_PASSWORD=&amp;quot;password&amp;quot; 507 &amp;amp; &lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To remove the container:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker rm 507&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;supported-testing-frameworks&#34;&gt;Supported Testing Frameworks&lt;/h2&gt;
&lt;p&gt;The space of Python testing is very fragmented, and there is not universal method of writing testcases. To make the process simple and extensible, we use the tox test framework, that simplifies the execution of the tests. We look at the standard locations to discover tests, and support the standard testing mechanisms. Here are our assumptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The tests are placed in the ${project}/test[s] directory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The requirements necessary are present in a requirements.txt file. Often developers specify multiple versions of this file. 	We look for all files in the repository that have a name starting with &amp;lsquo;requirements&amp;rsquo; to include for installation in the virtualenv.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The supported methods of testing the project are: setup.py with a test recipe, py.tests, nosetests, and plain old unittests.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;known-issues-and-fixes&#34;&gt;Known issues and fixes&lt;/h2&gt;
&lt;p&gt;When running &lt;code&gt;tox&lt;/code&gt; in the macOS terminal the following error might ocurr:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;unknown locale: UTF-8 in Python&lt;/code&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Trusted Capsules</title>
      <link>/project/trusted_capsules/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      <guid>/project/trusted_capsules/</guid>
      <description>&lt;p&gt;Security of data is tightly coupled to its access policy. However, in practice, a data owner has control of his data&amp;rsquo;s access policies only as far as the boundaries of his own systems. In this paper, we introduce graduated access control, which provides mobile, programmable, and dynamically-resolving policies for access control that extends a data owner&amp;rsquo;s policies across system boundaries. We realize this through a novel data-centric abstraction called trusted capsules and its associated system, the trusted data monitor.&lt;/p&gt;
&lt;p&gt;A trusted capsule couples data and policy into a single mobile unit. A capsule is backwards-compatible and is indistinguishable from a regular file to applications. In coordination with the trusted data monitor a capsule provides data integrity and confidentiality on remote devices, strong authentication to a trusted capsule service, and supports nuanced and dynamic access control decisions on remote systems. We implemented our data monitor using ARM TrustZone.&lt;/p&gt;
&lt;p&gt;We show that graduated access control can express novel and useful real world policies, such as revocation, remote monitoring, and risk-adaptable disclosure. We illustrate trusted capsules for different file formats, including JPEG, FODT, and PDF. We also show compatibility with unmodified applications, such as LibreOffice Writer, Evince, and VLC.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
